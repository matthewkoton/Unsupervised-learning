{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-q-stI7CvEY"
   },
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 004 - Part IV\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 1.0.000 | 09/09/2023 | Royi Avital | First version                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLnxt7PzCvEa"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_08/Exercise0004Part004.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T09:30:06.492269Z",
     "start_time": "2022-02-02T09:30:06.220934Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 2861,
     "status": "error",
     "timestamp": 1695485329923,
     "user": {
      "displayName": "Matthew Koton",
      "userId": "04644453353633690104"
     },
     "user_tz": -180
    },
    "id": "MsWZArTfCvEa",
    "outputId": "f8d15e29-26c0-4187-ded7-c5ef83168164"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a318b561db6c>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsomap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mumap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUMAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Computer Vision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap, MDS, TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from umap import UMAP\n",
    "\n",
    "# Computer Vision\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQieU_0VCvEb"
   },
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahm5JnCvCvEb"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# %matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DRUCLDmCvEc"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FILE_URL   = r'https://drive.google.com/uc?export=download&confirm=9iBg&id=1UXLdZgXwClgwZVszRq88UaaN2nvgMFiC'\n",
    "DATA_FILE_NAME  = r'BciData.npz'\n",
    "\n",
    "TOTAL_RUN_TIME = 90 #<! Don't touch it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oMXVgRjCvEc"
   },
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "\n",
    "def Plot2DScatter(mX: np.ndarray, hA: plt.Axes, vC: np.ndarray = None) -> None:\n",
    "    m = mX.min()\n",
    "    M = mX.max()\n",
    "    if vC is not None:\n",
    "        hA.scatter(*mX.T, s = 50,  c = vC, edgecolor = 'k', alpha = 1)\n",
    "    else:\n",
    "        hA.scatter(*mX.T, s = 50,  c = 'lime', edgecolor = 'k', alpha = 1)\n",
    "    hA.set_xlim([m, M])\n",
    "    hA.set_ylim([m, M])\n",
    "    hA.set_xlabel('$x_1$')\n",
    "    hA.set_ylabel('$x_2$')\n",
    "\n",
    "\n",
    "def PlotLabelsHistogram(vY: np.ndarray, hA = None, lClass = None, xLabelRot: int = None) -> plt.Axes:\n",
    "\n",
    "    if hA is None:\n",
    "        hF, hA = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "    vLabels, vCounts = np.unique(vY, return_counts = True)\n",
    "\n",
    "    hA.bar(vLabels, vCounts, width = 0.9, align = 'center')\n",
    "    hA.set_title('Histogram of Classes / Labels')\n",
    "    hA.set_xlabel('Class')\n",
    "    hA.set_ylabel('Number of Samples')\n",
    "    hA.set_xticks(vLabels)\n",
    "    if lClass is not None:\n",
    "        hA.set_xticklabels(lClass)\n",
    "\n",
    "    if xLabelRot is not None:\n",
    "        for xLabel in hA.get_xticklabels():\n",
    "            xLabel.set_rotation(xLabelRot)\n",
    "\n",
    "    return hA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iyHl_APCvEc"
   },
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Don't use `pip install` on the submitted notebook!  \n",
    "   If you need a package that is not imported above use **the dedicated cell**.  \n",
    "   Comment what do you need the package for and the version needed.\n",
    " - If you need functions from previous notebook copy them into a file called `AuxFun.py`.  \n",
    "   Import the function in the dedicated cell.\n",
    " - Submission in groups (Single submission per group).\n",
    " - The submission files should have the format: `<fileName>_GRP_<#>`.  \n",
    "   For instance, `Exercise001Part002_GRP_A.ipynb` or `AuxFun_GRP_A.py`.\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Good Luck!\n",
    "\n",
    "<font color='red'>Total run time must be **less than `TOTAL_RUN_TIME` seconds**</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY2HPuU5CvEc"
   },
   "outputs": [],
   "source": [
    "# Run Time\n",
    "print(f'The total run time must not exceed: {TOTAL_RUN_TIME} [Sec]')\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj-_3ZksCvEd"
   },
   "source": [
    "* <font color='brown'>(**#**)</font> The `Import Packages` section above imports most needed tools to apply the work. Please use it.\n",
    "* <font color='brown'>(**#**)</font> You may replace the suggested functions to use with functions from other packages.\n",
    "* <font color='brown'>(**#**)</font> Whatever not said explicitly to implement maybe used by a 3rd party packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ1XIr7SCvEd"
   },
   "source": [
    "## Team Members\n",
    "\n",
    "- `Matthew_koton_806614`\n",
    "- `Aviv_Ples_318357233`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nph7iofkCvEd"
   },
   "outputs": [],
   "source": [
    "# Students Packages to Import\n",
    "# If you need a package not listed above, use this cell\n",
    "# Do not use `pip install` in the submitted notebook\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgJzdyYyCvEd"
   },
   "source": [
    "## Generate / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwzf7RDLCvEe"
   },
   "outputs": [],
   "source": [
    "# Download Data\n",
    "# This section downloads data from the given URL if needed.\n",
    "\n",
    "if (DATA_FILE_NAME != 'None') and (not os.path.exists(DATA_FILE_NAME)):\n",
    "    urllib.request.urlretrieve(DATA_FILE_URL, DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVa9A8AGCvEe"
   },
   "source": [
    "## 9. T-SNE and UMAP\n",
    "\n",
    "In this section we'll use the _t-SNE_ and _UMAP_ algorithms to analyze EEG Signals in the context of _Brain Computer Interface_ (BCI).  \n",
    "\n",
    "### The BCI Data Set\n",
    "\n",
    "The Brain Computer Interfaces (BCI) Data from [BCI Competition IV](https://www.bbci.de/competition/iv/).  \n",
    "Specifically we'll use [data set 2a](https://www.bbci.de/competition/iv/#dataset2a) provided by the Institute for Knowledge Discovery (Laboratory of Brain Computer Interfaces), Graz University of Technology, (Clemens Brunner, Robert Leeb, Gernot Müller-Putz, Alois Schlögl, Gert Pfurtscheller).  \n",
    "This is a recording of EEG signals while the subject is doing a cued movement of the left hand, right hand, feet or tongue.\n",
    "\n",
    "The data is composed of:\n",
    "\n",
    " * 22 EEG channels (0.5-100Hz; notch filtered).\n",
    " * Sampling Rate of 250 [Hz] for 4 [Sec] for total of 1000 samples.\n",
    " * 4 classes: _left hand_, _right hand_, _feet_, _tongue_.\n",
    " * 9 subjects.\n",
    " * 287 measurements.\n",
    "\n",
    "</br>\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You should install [UMAP](https://umap-learn.readthedocs.io/en/latest/index.html) on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzvXFS4QCvEe"
   },
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "\n",
    "dData = np.load(DATA_FILE_NAME)\n",
    "mX    = dData['mX1']\n",
    "vY    = dData['vY1']\n",
    "\n",
    "# Sample: An observation of a subject.\n",
    "# Measurement: Sample in time of the EEG signal.\n",
    "# Channel: EEG Channel.\n",
    "numSamples, numMeasurements, numChannels = mX.shape\n",
    "lLabel = ['Left Hand', 'Right Hand', 'Foot', 'Tongue'] #<! The labels\n",
    "\n",
    "print(f'The data shape: {mX.shape}')\n",
    "print(f'The number of samples: {mX.shape[0]}')\n",
    "print(f'The number of measurements per sample: {mX.shape[1]}')\n",
    "print(f'The number of EEG channels: {mX.shape[2]}')\n",
    "print(f'The classes labels: {np.unique(vY)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-fk1beqCvEe"
   },
   "source": [
    "* <font color='brown'>(**#**)</font> In the above `sample` is used per object detected.\n",
    "* <font color='brown'>(**#**)</font> In the above `measurement` is used to describe the time sample (Like in Signal Processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmAJ2hUmCvEf"
   },
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "\n",
    "numRowsPlot = 3\n",
    "numColsPlot = 2\n",
    "\n",
    "numPlots = numRowsPlot * numColsPlot\n",
    "\n",
    "hF, hAs = plt.subplots(nrows = numRowsPlot, ncols = numColsPlot, figsize = (18, 10))\n",
    "hAs = hAs.flat\n",
    "\n",
    "vIdx = np.random.choice(numSamples, numPlots, replace = False)\n",
    "\n",
    "for sampleIdx, hA in zip(vIdx, hAs):\n",
    "    mXX = mX[sampleIdx, :, :]\n",
    "    hA.plot(mXX)\n",
    "    hA.set_title(f'EEG Signals of Sample {sampleIdx:04d} with Label {lLabel[vY[sampleIdx]]}')\n",
    "    hA.set_xlabel('Measurement Index')\n",
    "    hA.set_ylabel('Measurement Value')\n",
    "\n",
    "hF.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjvjlCEZCvEf"
   },
   "outputs": [],
   "source": [
    "# Plot the Data\n",
    "# Show a shifted and scaled channels at a single plot.\n",
    "# You may run it several times to observe different measurements.\n",
    "\n",
    "numSamples, numMeasurements, numChannels = mX.shape #<! Samples, Time Samples, Channels\n",
    "idx     = np.random.randint(numSamples)\n",
    "mXi     = mX[idx, :, :].copy()\n",
    "yi      = vY[idx]\n",
    "\n",
    "# Normalizing and Vertically Shifting\n",
    "mXi -= mXi.mean(0)\n",
    "mXi /= 20\n",
    "mXi += np.arange(numChannels)[None, :]\n",
    "vT   = np.linspace(0, 4, numMeasurements, endpoint = False)\n",
    "\n",
    "hF, hA = plt.subplots(figsize = (10, 6))\n",
    "hA.plot(vT, mXi)\n",
    "hA.set_title (f'Raw EEG Data\\nTrue Label = {lLabel[yi]}')\n",
    "hA.set_xlabel('Time [Sec]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_o59ptOdCvEf"
   },
   "outputs": [],
   "source": [
    "# Histogram of Labels\n",
    "\n",
    "hA = PlotLabelsHistogram(vY, lClass = lLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0U9u3JECvEf"
   },
   "source": [
    "* <font color='brown'>(**#**)</font> The data is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr_i6uSQCvEf"
   },
   "source": [
    "### 9.1. Processing RAW Data\n",
    "\n",
    "In this section we'll compare 4 dimensionality reduction methods:\n",
    "\n",
    " - IsoMap.\n",
    " - MDS.\n",
    " - t-SNE.\n",
    " - UMAP.\n",
    "\n",
    "We'll reduce the data dimension to `d = 2` and use the reference labels to display result.\n",
    "\n",
    "The steps:\n",
    "\n",
    "1. Data Pre Processing  \n",
    "     * Reshape data into `mXRaw` such that each measurement is a row.  \n",
    "       Namely the data should have dimensions of `287 x 22_000`.  \n",
    "     * Apply dimensionality reduction using PCA to keep most of the data energy.\n",
    "2. Set Parameters  \n",
    "   Set parameters of each method to get results.  \n",
    "   Set the amount of energy preserved using the PCA pre processing.\n",
    "   **No need for grid search, just try and error of few values**.\n",
    "3. Apply the Transform  \n",
    "   Apply the transform on the data.  \n",
    "   The low dimensional data should be in 2D space.  \n",
    "4. Display Results  \n",
    "   Create a subplot per method showing the results and the used parameters.  \n",
    "\n",
    "* <font color='brown'>(**#**)</font> No need to self implement any of the methods. You should use SciKit Learn's implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLAhy3Q4CvEf"
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Pre Process data:\n",
    "#    * Reshape to (287 x 22_000).\n",
    "#    * Apply PCA to preserve `relEnergy` of the energy.\n",
    "# 2. Apply Dimensionality Reduction (d = 2) using IsoMap, MDS, t-SNE and UMAP.\n",
    "#    Choose a reasonable parameters for each.\n",
    "# 3. Display the Low Dimensionality data.\n",
    "#    Include the parameters in the title of each method.\n",
    "# !! The output should be a figure of 1x4 axes (2D Scatter and 3D Scatter per method).\n",
    "# !! You may use `Plot2DScatter()` for displaying the the data.\n",
    "\n",
    "mXRaw = mX.reshape(287,22000)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(mXRaw)\n",
    "mXRaw_pca = pca.fit_transform(mXRaw)\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "mXIsoMap = isomap.fit_transform(mXRaw_pca)\n",
    "\n",
    "mds = MDS(n_components=2)\n",
    "mXMDS = mds.fit_transform(mXRaw_pca)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "mXTSNE = tsne.fit_transform(mXRaw_pca)\n",
    "\n",
    "umap = UMAP(n_components=2)\n",
    "mXUMAP = umap.fit_transform(mXRaw_pca)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "fig.suptitle(\"Dimensionality Reduction Comparison\")\n",
    "\n",
    "\n",
    "##plotting\n",
    "\n",
    "# IsoMap\n",
    "Plot2DScatter(mXIsoMap, axes[0, 0], vY)\n",
    "axes[0, 0].set_title(\"IsoMap\")\n",
    "\n",
    "# MDS\n",
    "Plot2DScatter(mXMDS, axes[0, 1], vY)\n",
    "axes[0, 1].set_title(\"MDS\")\n",
    "\n",
    "# t-SNE\n",
    "Plot2DScatter(mXTSNE, axes[1, 0], vY)\n",
    "axes[1, 0].set_title(\"t-SNE\")\n",
    "\n",
    "# UMAP\n",
    "Plot2DScatter(mXUMAP, axes[1, 1], vY)\n",
    "axes[1, 1].set_title(\"UMAP\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P213wUACvEg"
   },
   "source": [
    "### 9.1.1 Question\n",
    "\n",
    "1. What's the purpose of the PCA pre process?\n",
    "2. Explain the results. Think in the context of being able to classify the body part in action.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDSGa4JICvEg"
   },
   "source": [
    "### 9.1.1 Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---\n",
    "\n",
    "the purpose of the pca is to reduce the dimensionality while still keeping most of the variance within the data\n",
    "\n",
    "The results are note good as the data is not seperated based on the body part in action. it is therefor difficult/impossible to classify or cluster using the above dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RioL48HxCvEg"
   },
   "source": [
    "### 9.2. Feature Engineering\n",
    "\n",
    "Form the above it is clear the RAW measurements are not a good representation of the data.  \n",
    "Since each sample is basically $\\boldsymbol{X}_{i}\\in\\mathbb{R}^{1000 \\times 22}$ we can work on the time axis of the data.  \n",
    "\n",
    "The strategy is as following:\n",
    "\n",
    " * Use the Covariance Matrix is a feature of the sample.\n",
    " * Use a metric optimized to covariance matrices.\n",
    "\n",
    "Do the following steps:\n",
    "\n",
    "1. Implements `GenCovMat()`  \n",
    "   For each sample $\\boldsymbol{X}_{i}\\in\\mathbb{R}^{1000 \\times 22}$, compute the covariance matrix $\\boldsymbol{C}_{i}\\in\\mathbb{R}^{22\\times22}$.  \n",
    "   You may use [`np.cov()`](https://numpy.org/doc/stable/reference/generated/numpy.cov.html).\n",
    "2. Implement `SpdMetric()`  \n",
    "   Given 2 SPD matrices in the form of vectors computes the geodesic distance between them.\n",
    "3. Apply the Feature Engineering  \n",
    "   The end of this process should be a matrix `mZ` with dimensions (287 x 22^2)\n",
    "4. Generate the Distance Matrix  \n",
    "   Using `SpdMetric()` generate the distance matrix of the data.  \n",
    "   The output should be a matrix `mD` with dimensions (287 x 287).\n",
    "\n",
    "#### The SPD Matrices Metric\n",
    "\n",
    "An optimized metric for the manifold of SPD Matrices, is given by the SPD Metric (`SpdMetric`):\n",
    "\n",
    "$$d\\left(\\boldsymbol{C}_{i},\\boldsymbol{C}_{j}\\right)=\\sqrt{\\sum_{i=1}^{d}\\log^{2}\\left(\\lambda_{i}\\left(\\boldsymbol{C}_{i}^{-1}\\boldsymbol{C}_{j}\\right)\\right)}$$\n",
    "\n",
    "Where ${\\lambda}_{i} \\left( \\cdot \\right)$ extract the $i$ -th eigen value of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5_SvejbCvEg"
   },
   "outputs": [],
   "source": [
    "def GenCovMat(mX: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the covariance matrices of the input data.\n",
    "    Args:\n",
    "        mX - Input data with shape (N x T x C)\n",
    "    Output:\n",
    "        mC - N covariance matrices with shape (N x C x C)\n",
    "    '''\n",
    "\n",
    "    #===========================Fill This===========================#\n",
    "    # 1. Calculate the covariance matrices array.\n",
    "    # !! Do not use any loop!\n",
    "\n",
    "    N, T, C = mX.shape\n",
    "\n",
    "    # Initialize an empty array to store the covariance matrices\n",
    "    mC = np.empty((N, C, C))\n",
    "\n",
    "    # Calculate the covariance matrix for each N\n",
    "    epsilon = 1e-5\n",
    "    for i in range(N):\n",
    "        xi = mX[i]\n",
    "\n",
    "        cov_matrix = np.cov(xi, rowvar=False)\n",
    "        #cov_matrix = cov_matrix + epsilon * np.eye(cov_matrix.shape[0])\n",
    "\n",
    "        mC[i] = cov_matrix\n",
    "    #===============================================================#\n",
    "\n",
    "    return mC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLIx_Y2GCvEg"
   },
   "outputs": [],
   "source": [
    "def SpdMetric(vP: np.ndarray, vQ: np.ndarray) -> float:\n",
    "    '''\n",
    "    Calculates the AIRM geodesic distance between two SPD matrices.\n",
    "    Args:\n",
    "        mP    - An SPD matrix in the form of a vector with shape (d^2, )\n",
    "        mQ    - An SPD matrix in the form of a vector with shape (d^2, )\n",
    "    Output:\n",
    "        geoDist - The geodesic distance, dist ≥ 0\n",
    "    '''\n",
    "\n",
    "    #===========================Fill This===========================#\n",
    "    # 1. Convert the vectors into a matrix.\n",
    "    # 2. Calculate the geodesic distance of SPD matrices.\n",
    "    # !! Do not use any loop!\n",
    "    # !! You may find `scipy.linalg.eigvalsh()` useful.\n",
    "\n",
    "    vP_reshaped = vP.reshape(22, 22)\n",
    "    vQ_reshaped = vQ.reshape(22, 22)\n",
    "\n",
    "    Ci_inv = np.linalg.inv(vP_reshaped)\n",
    "\n",
    "    product_matrix = np.dot(Ci_inv, vQ_reshaped)\n",
    "\n",
    "    eigenvalues, _ = np.linalg.eig(product_matrix)\n",
    "\n",
    "    epsilon = 0\n",
    "    eigenvalues = np.maximum(eigenvalues, epsilon)\n",
    "\n",
    "    log_squared_eigenvalues = np.log(eigenvalues)**2\n",
    "\n",
    "    geoDist = np.sqrt(np.sum(log_squared_eigenvalues))\n",
    "    #===============================================================#\n",
    "\n",
    "    return geoDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBMA40OICvEg"
   },
   "outputs": [],
   "source": [
    "# Process Data\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Generate the covariance matrices.\n",
    "# 2. Reshape data into the samples matrix.\n",
    "# 3. Calculate the distance matrix.\n",
    "# !! Don't use any loop!\n",
    "# !! You may use `pairwise_distances()` in order to avoid loops.\n",
    "\n",
    "cov_matrixes = GenCovMat(mX)\n",
    "\n",
    "cov_matrixes_reshaped = cov_matrixes.reshape(287,22*22)\n",
    "\n",
    "mD = pairwise_distances(cov_matrixes_reshaped, metric=SpdMetric)\n",
    "#===============================================================#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdnl5BHlCvEg"
   },
   "outputs": [],
   "source": [
    "# Plot the Low Dimensional Data\n",
    "# This shows the result using IsoMap with SpdMetric.\n",
    "d=2\n",
    "\n",
    "oIsoMapDr = Isomap(n_neighbors = 3, n_components = d, metric = 'precomputed')\n",
    "\n",
    "hF = plt.figure(figsize = (12, 6))\n",
    "\n",
    "mZi = oIsoMapDr.fit_transform(mD)\n",
    "hA = hF.add_subplot()\n",
    "Plot2DScatter(mZi, hA, vY)\n",
    "hA.set_title(f'IsoMap (SPD Metric) with d = {d}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbKhcExxCvEh"
   },
   "source": [
    "#### 9.2.1. Question\n",
    "\n",
    "In the above the _IsoMap_ is used.  \n",
    "If one would like to use SciKit Learn's _Spectral Embedding_ (See [`SpectralEmbedding`](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html)) one need to supply _Affinity Matrix_ (See `affinity` parameter).  \n",
    "Describe how would you generate such matrix based on `SpdMetric()`.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> SciKit Learn's _Spectral Embedding_ is equivalent to _Laplacian Eigenmaps_ on lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWT4MzFuCvEh"
   },
   "source": [
    "#### 9.2.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---\n",
    "we can use SpdMetric() in order to caluclate the distances between each spd matrix and then use the the knn algorithm in order to calculate each spd matrixes k nearest neighbours in order to construct the affinity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZQcH4vLCvEh"
   },
   "source": [
    "### 9.3. Dimensionality Reduction and Classification on Engineered Data\n",
    "\n",
    "In this section we'll focus on `t-SNE` and `UMAP`.  \n",
    "\n",
    "1. Apply Dimensionality Reduction  \n",
    "   Apply `t-SNE` and / or `UMAP` on the engineered data.  \n",
    "   Make sure to use the appropriate options to utilize the metric.  \n",
    "   Apply this on the whole data.\n",
    "2. Apply Classification  \n",
    "   Apply a classifier (From SciKit Learn, Neural Networks excluded) on the low dimensional data.\n",
    "3. Measure Performance of the Classifier  \n",
    "   Apply **leave one out cross validation** with score based on **accuracy**.  \n",
    "   You should use [`cross_val_predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html).  \n",
    "   This will generate a vector of 287 predictions.\n",
    "4. Display Results  \n",
    "   Display the confusion matrix and the total accuracy.\n",
    "\n",
    "**This is a competition**:\n",
    "\n",
    " * The group with the 1st highest score will get 4 bonus points.\n",
    " * The group with the 2nd highest score will get 2 bonus points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phsQxfoYCvEh"
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Use t-SNE and/or UMAP for Dimensionality Reduction.\n",
    "# 2. On the output of (1) apply a classifier from SciKit Learn.\n",
    "# 3. To measure the performance use `cross_val_predict()` with accuracy as the score.\n",
    "# 4. Display the confusion matrix of the result of the `cross_val_predict()`.\n",
    "# !! Use leave one out as the validation policy.\n",
    "# !! Use the `SpdMetric()` for UMAP / t-SNE!\n",
    "# !! This is a competition, optimize the hyper parameters of each step for best accuracy.\n",
    "# !! No use of Neural Net based classifiers!\n",
    "# !! If you use t-SNE, make sure to make it non random (See `init` and `random_state`).\n",
    "# !! Pay attention to the run time limitation of the whole notebook.\n",
    "\n",
    "cov_matrixes = GenCovMat(mX)\n",
    "cov_matrixes_reshaped = cov_matrixes.reshape(287,22*22)\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, metric=SpdMetric)\n",
    "mZ_tsne = tsne.fit_transform(cov_matrixes_reshaped)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "y_pred_tsne = cross_val_predict(clf, mZ_tsne, vY, n_jobs=-1)\n",
    "\n",
    "accuracy_tsne = accuracy_score(vY, y_pred_tsne)\n",
    "\n",
    "print(\"accuracy: \", accuracy_tsne)\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVsnNSGxCvEh"
   },
   "source": [
    "#### 9.3.1. Question\n",
    "\n",
    "In the above we had the whole data for the _dimensionality reduction_ step.  \n",
    "Assume we use a method without _out of sample extension_.  \n",
    "In the case above, how would you handle a new data point? Explain the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_6gcMZNCvEh"
   },
   "source": [
    "#### 9.3.1. Solution\n",
    "\n",
    "<font color='red'>??? Fill the answer here ???</font>\n",
    "\n",
    "---\n",
    "if we use a method without an out of sample extension we will have to recompute the lower dimensional representation of our whole data set with the new data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RpllOXgCvEh"
   },
   "outputs": [],
   "source": [
    "# Run Time\n",
    "# Check Total Run Time.\n",
    "# Don't change this!\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "totalRunTime = endTime - startTime\n",
    "print(f'Total Run Time: {totalRunTime} [Sec].')\n",
    "\n",
    "if (totalRunTime > TOTAL_RUN_TIME):\n",
    "    raise ValueError(f'You have exceeded the allowed run time as {totalRunTime} > {TOTAL_RUN_TIME}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
